{"file": "2212.10496.json", "summerization_type": "map_reduce", "summary": " This paper presents the HyDE model, a hybrid deep retrieval model that combines a generative language model and a contrastive encoder to improve retrieval performance. Experiments show that HyDE can outperform non-Contriever models and fine-tuned mContrieverFT models on multilingual retrieval tasks. Additionally, the paper discusses the use of finetuned language models as zero-shot learners, Approximate Nearest Neighbor Negative Contrastive Learning for dense text retrieval, and Combating Distribution Shifts in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning. It also introduces Mr. TyDi, a multi-lingual benchmark for dense retrieval."}