{"file": "2203.11171.json", "summerization_type": "map_reduce", "summary": "\n\nThis paper proposes a self-consistency approach to improve chain of thought reasoning in language models. The approach samples a diverse set of reasoning paths and marginalizes out the sampled reasoning paths to aggregate final answers. Results show that self-consistency significantly improves the accuracy of arithmetic, commonsense, and symbolic reasoning tasks over chain-of-thought prompting, and achieves new state-of-the-art results on almost all tasks. It is also useful for collecting rationales and providing uncertainty estimates."}