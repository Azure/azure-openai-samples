{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - PII Chekcer\n",
    "\n",
    "In this demo, we show how to create a chain using Azure OpenAI service to prevent exposure of PII information.\n",
    "\n",
    "We are creating a process which uses Azure OpenAI to self-evaluate the answer, identify potential PII information and remediate before the answer is returned to end user."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Summaries for extracted documents\n",
    "\n",
    "In this demo, we show how to generate one summary for a large document. The answer generated will likely include some PII data like address or phone number.\n",
    "\n",
    "\n",
    "## Step 1: Generate a summary from existing large document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "file = 'data/SAMPLE-RESIDENTIAL-REPORT.json'\n",
    "\n",
    "llm = AzureOpenAI(temperature=0, deployment_name=os.getenv('DEPLOYMENT_NAME'), max_tokens=1000)\n",
    "\n",
    "with open(file) as f:\n",
    "    file_json = json.loads(f.read())\n",
    "\n",
    "docs = [Document(page_content = page['page_content']) for page in file_json['content']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kaizen Safety Solutions, LLC conducted an environmental analysis of 123 Main Street, a single family residence that had been damaged by a fire. The analysis found that the air quality was within acceptable limits, but that there were elevated levels of asbestos and lead present in the soil. The estimated cost of the project is $25,000, and the action plan includes the removal and replacement of the soil, as well as monitoring of the area for asbestos and lead levels.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"Below is a environmental analysis report, review the details and summerize claim details, cost and action plan:\n",
    "\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "summary_chain = load_summarize_chain(llm, \n",
    "                             chain_type=\"map_reduce\", \n",
    "                             map_prompt=PROMPT, \n",
    "                             combine_prompt=PROMPT)\n",
    "summary_response = summary_chain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "print(summary_response['output_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: We review the summary and identify any PII data\n",
    "\n",
    "In this step, we ask GPT model to evaluate the answer generated in previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- 123 Main Street (address)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "pii_prompt_template = \"\"\"Review following text and create a bullet list of any personally identifiable information (PII) such as names, addresses, phone numbers, email addresses, social security numbers, or any other information that could be used to identify an individual.\n",
    "\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "PII LIST:\"\"\"\n",
    "PII_PROMPT = PromptTemplate(template=pii_prompt_template, input_variables=[\"text\"])\n",
    "pii_chain = LLMChain(llm=llm, \n",
    "                     prompt=PII_PROMPT, \n",
    "                     verbose=False,\n",
    "                     output_key='PII')\n",
    "response = pii_chain.predict(text=summary_response['output_text'])\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step: We revise the summary and redact PII information from the summary\n",
    "\n",
    "This is remediation step, where we ask GPT to rewrite the answer and remove the PII data identified in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kaizen Safety Solutions, LLC conducted an environmental analysis of a single family residence that had been damaged by a fire. The analysis found that the air quality was within acceptable limits, but that there were elevated levels of asbestos and lead present in the soil. The estimated cost of the project is $25,000, and the action plan includes the removal and replacement of the soil, as well as monitoring of the area for asbestos and lead levels.\n"
     ]
    }
   ],
   "source": [
    "final_prompt_template = \"\"\"Use the PII list, redact all PII information in the summary and rewrite the summary:\n",
    "\n",
    "\n",
    "Summary:\n",
    "\"{text}\"\n",
    "\n",
    "PII List:\n",
    "\"{PII}\"\n",
    "\n",
    "REWRITTEN SUMMARY:\"\"\"\n",
    "FINAL_PROMPT = PromptTemplate(template=final_prompt_template, input_variables=[\"text\", \"PII\"])\n",
    "final_chain = LLMChain(llm=llm, \n",
    "                     prompt=FINAL_PROMPT, \n",
    "                     output_key='revised_summary',\n",
    "                     verbose=False)\n",
    "revise_summary = final_chain.predict(text=summary_response['output_text'], PII=response)\n",
    "print(revise_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
