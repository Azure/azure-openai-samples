{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Podcast Synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/ft-interview-transcription.txt\"\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# convert list to str\n",
    "content = ' '.join(content) \n",
    "#print(content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a succeeded deployment of \"text-davinci-003\" that supports text completion with id: text-davinci-003.\n"
     ]
    }
   ],
   "source": [
    "# id of desired_model\n",
    "desired_model = 'text-davinci-003' # suitable for text generation\n",
    "desired_capability = 'completion'\n",
    "\n",
    "# list models deployed with\n",
    "deployment_id = None\n",
    "result = openai.Deployment.list()\n",
    "\n",
    "for deployment in result.data:\n",
    "    if deployment[\"status\"] != \"succeeded\":\n",
    "        continue\n",
    "    \n",
    "    model = openai.Model.retrieve(deployment[\"model\"])\n",
    "\n",
    "    # check if desired_model is deployed, and if it has 'completion' capability\n",
    "    if model[\"id\"] == desired_model and model['capabilities'][desired_capability]:\n",
    "        deployment_id = deployment[\"id\"]\n",
    "        \n",
    "# if no model deployed, deploy one\n",
    "if not deployment_id:\n",
    "    print('No deployment with status: succeeded found.')\n",
    "\n",
    "    # Deploy the model\n",
    "    print(f'Creating a new deployment with model: {desired_model}')\n",
    "    result = openai.Deployment.create(model=desired_model, scale_settings={\"scale_type\":\"standard\"})\n",
    "    deployment_id = result[\"id\"]\n",
    "    print(f'Successfully created {desired_model} that supports text {desired_capability} with id: {deployment_id}.')\n",
    "else:\n",
    "    print(f'Found a succeeded deployment of \"{desired_model}\" that supports text {desired_capability} with id: {deployment_id}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text chunks generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generator that split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def chunk_generator(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_api(document, prompt_postfix, max_tokens):\n",
    "    prompt = prompt_postfix.replace('<document>',document)\n",
    "    #print(f'>>> prompt : {prompt}')\n",
    "\n",
    "    response = openai.Completion.create(  \n",
    "    deployment_id=deployment_id, \n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1,\n",
    "    frequency_penalty=1,\n",
    "    presence_penalty=1,\n",
    "    stop='###')\n",
    "\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(content, prompt_postfix):\n",
    "    import tiktoken\n",
    "\n",
    "    synopsis_chunck = []\n",
    "    n = 2000 # max tokens for chuncking\n",
    "    max_tokens = 1000 # max tokens for response\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "    # Generate chunkcs    \n",
    "    chunks = chunk_generator(content, n, tokenizer)\n",
    "\n",
    "    # Decode chunk of text\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    # Request api\n",
    "    for chunk in text_chunks:\n",
    "        synopsis_chunck.append(request_api(chunk, prompt_postfix, max_tokens))\n",
    "        #print(chunk)\n",
    "        #print('>>> synopsis: \\n' + synopsis_chunck[-1])\n",
    "\n",
    "    # Synopsis\n",
    "    synopsis = ' '.join(synopsis_chunck)\n",
    "\n",
    "    return synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Financial Times' US financial commentator Robert Armstrong discusses the collapse of Silicon Valley Bank and why it is not a repeat of the 2008 financial crisis. He explains that two factors led to SVB's collapse: bad decisions at the bank and a rapid increase in interest rates. Rob also outlines how banks operate, what went wrong with SVB specifically, and whether there are larger systemic reasons for this. He further explains why we have a two-tiered system when it comes to banking regulations, as well as how Dodd-Frank Act rollback may or may not have played a role in this situation. Finally, he reassures listeners that so long as people don't panic, everything should be fine and that deposits under $250k are covered by the US government. Robert Armstrong, a financial expert, discusses the recent collapse of SVB and its implications for banking regulation. He explains that banks are now better capitalised than before 2008 due to regulations put in place after the crisis. He also suggests that investors should be careful when depositing money into banks and look at their capital structure. Finally, he predicts that bank equity capital will become more expensive and have a slowing effect on the economy as investors become wary of putting money into banks following this incident.\n"
     ]
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nSummarise the transcript of a podcast above into a synopsis. \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "synopsis = get_synopsis(content, prompt_postfix)\n",
    "\n",
    "print(synopsis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nTranslate synopsis into Mandarin.  \n",
    "  \\nTranslation : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美国金融评论家罗伯特·阿姆斯特朗（Robert Armstrong）在《金融时报》中讨论了硅谷银行的崩溃，以及为什么这不是2008年金融危机的重演。 他解释说，导致SVB倒闭的两个因素是银行内部的不当决定和利率急剧上升。 罗布还概述了银行如何运作、SVB具体出了什么问题以及是否存在更大的系统原因。 此外，他还说明了我们在银行监管方面存在一套分层体制，并提出道德弗兰克法案(Dodd-Frank Act) 回退可能或可能不会对此情况产生影响。 最后，他保证人民只要不惊慌就应该一切安好；而250,000美元之下的储备将由美国政府承保。 金融专家 Robert Armstrong 讨论了 SVB 最近的崩盘及其对银行监管意味.  他 解释 说 ： 由 于 2008 年 后 所 颁 布 的 相 关 法 规 ； 银 行 的 资 本 水 平 比 2008年之前已有所加强。 \n",
      "  \n",
      "此外, 也建议投���者在存入钱时注意看看它们的杠杆情况, 最后, 预测随之而来, 高风标准将使得 bank equity capital (bank equity capital) 成本上升 ,并放緩效能.\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 1000\n",
    "translation = request_api(synopsis, prompt_postfix, max_tokens)\n",
    "print(translation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "美国金融评论家罗伯特·阿姆斯特朗（Robert Armstrong）在《金融时报》上就硅谷银行的崩溃进行了讨论，并且说明这不是2008年金融危机的复制。他解释说，导致SVB倒闭的原因有两方面：一是银行内部出现了不当决定; 二是利率急剧上升。此外，Rob 还概述了银行如何运作、SVB具体出现什么问题以及是否存在更大的体系性原因。此外，他还详细说明了为什么我们在监管方面存在双标准制度, 以及道德弗兰克法案(Dodd-Frank Act) 的退减对此情况会不会造成影响。最后,  Robert Armstrong 向听众保证, 只要人民不惊慌失措, 情况应当一切安好, 250k 美元之下的储户由美国政府承保.\n",
    "Robert Armstrong 金融专家提出了 SVB 最新崩盘及其对相关监管带来的影响。 他表明由于 2008 年危机之后所施加的法律法规使得如今的银行已然比 2008 年时更加强壮。 此外， 也告诫投者将存款存入需要留意看看能耐性情况。 最后 ， Robert Armstrong 预测随之考勒将使得 bank equity capital 更加昂���耗时曲緩效应将随之考勒使效能受到影响."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tag Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nGenerate 2 to 3 tag lines based on the podcast synopsis above.\n",
    "\"\"\"\n",
    "#print(prompt_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Get the facts on Silicon Valley Bank's collapse and its implications for banking regulations.\n",
      "2. Don't panic: Robert Armstrong explains why deposits under $250k are safe.\n",
      "3. Learn how Dodd-Frank Act rollback may have played a role in SVB's collapse with Robert Armstrong.\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 500\n",
    "tag_lines = request_api(synopsis, prompt_postfix, max_tokens)\n",
    "print(tag_lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Search Engine Optimised (SEO) Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nGenerate 5 search engine optimised keywords based on text above.  \n",
    "\"\"\"\n",
    "#print(prompt_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(content, prompt_postfix):\n",
    "    import tiktoken\n",
    "\n",
    "    keywords_chunck = []\n",
    "    n = 2000 # max tokens for chuncking\n",
    "    max_tokens = 100\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "    # Generate chunkcs    \n",
    "    chunks = chunk_generator(content, n, tokenizer)\n",
    "\n",
    "    # Decode chunk of text\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    # Request api\n",
    "    for chunk in text_chunks:\n",
    "        keywords_chunck.append(request_api(chunk, prompt_postfix, max_tokens))\n",
    "\n",
    "    # Keywords\n",
    "    keywords = ' '.join(keywords_chunck)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Silicon Valley Bank collapse\n",
      "2. Robert Armstrong financial expert\n",
      "3. Banking regulations post-2008 crisis\n",
      "4. Dodd-Frank Act rollback \n",
      "5. US government deposit insurance\n"
     ]
    }
   ],
   "source": [
    "keywords = get_keywords(synopsis, prompt_postfix)\n",
    "print(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
